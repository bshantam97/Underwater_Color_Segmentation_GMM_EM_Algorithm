{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the average colour histogram for each of the RGB Colour channels\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "\n",
    "path_to_image_buoy1 = 'C:\\\\Users\\\\shant\\\\Underwater_Color_Segmentation_GMM_EM_Algorithm\\\\data\\\\buoy1\\\\train\\\\buoy156.png'\n",
    "path_to_image_buoy2 = 'C:\\\\Users\\\\shant\\\\Underwater_Color_Segmentation_GMM_EM_Algorithm\\\\data\\\\buoy2\\\\train\\\\buoy108.png'\n",
    "path_to_image_buoy3 = 'C:\\\\Users\\\\shant\\\\Underwater_Color_Segmentation_GMM_EM_Algorithm\\\\data\\\\buoy3\\\\train\\\\buoy28.png'\n",
    "img1 = cv2.imread(path_to_image_buoy1)\n",
    "img2 = cv2.imread(path_to_image_buoy2)\n",
    "img3 = cv2.imread(path_to_image_buoy3)\n",
    "cv2.imshow('img1',img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise step of em algorithm\n",
    "def initialise_step(n, d, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    n - number of datapoints\n",
    "    d - dimension of the gaussian\n",
    "    k - number of the gaussians\n",
    "    \n",
    "    Outputs:\n",
    "    weights_gaussian - weight of the gaussians, size (k)\n",
    "    mean_gaussian - mean of the gaussians, size (k x d)\n",
    "    covariance_matrix_gaussian - covariance of the gaussians, size (k x d x d)\n",
    "    probability_values - probability of the datapoint being in the k-gaussians, size (n x k)\n",
    "    \"\"\"\n",
    "        \n",
    "    # initialise weights\n",
    "    weights_gaussian = np.zeros(k)\n",
    "    for index in range(0, k):\n",
    "        weights_gaussian[index] = (1.0 / k)\n",
    "    \n",
    "    # initialise mean\n",
    "    mean_gaussian = np.zeros((k, d))\n",
    "    \n",
    "    # initialise covariance\n",
    "    covariance_matrix_gaussian = np.zeros((k, d, d))\n",
    "    \n",
    "    # randomly initialise probability\n",
    "    probability_values = np.zeros((n, k))\n",
    "    for index in range(0, n):\n",
    "        probability_values[index][np.random.randint(0, k)] = 1\n",
    "        \n",
    "    # return the arrays\n",
    "    return (weights_gaussian, mean_gaussian, covariance_matrix_gaussian, probability_values)\n",
    "\n",
    "# Fit a gaussian using the datapoints obtained using the histogram\n",
    "def fit_gaussian(image):\n",
    "    \n",
    "    color = ('b' , 'g' , 'r') # The number of color channels\n",
    "    \n",
    "    for i, col in enumerate(color):\n",
    "        \n",
    "        # Calculate the histogram for the Red Green and Blue color channel\n",
    "        # If input is grayscale the channels = [0] but for color image the channels can be [0], [1], [2]\n",
    "        histr = cv2.calcHist([image],[i],None,[256],[0,256])\n",
    "\n",
    "        (mu , sigma) = norm.fit(histr) # Maximum likelihood estimate\n",
    "        bins = np.linspace(0,255,256)\n",
    "        print(\"mu:\" + str(mu) + \"sigma:\" + str(sigma))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(bins, norm.pdf(bins,mu,(sigma)),color=col); plt.xlim([0,256])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(histr,color = col); plt.xlim([0,256])\n",
    "    plt.show()\n",
    "\n",
    "# gaussian estimation for expectation step\n",
    "def gaussian_estimation(data_point, mean, covariance, dimension):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    data_point - data point of the gaussian, size (1 x d)\n",
    "    mean - mean of the gaussian, size (1 x d)\n",
    "    covariance - covariance of the gaussian, size (1 x d x d)\n",
    "    dimension - dimension of the gaussian\n",
    "    \n",
    "    Outputs:\n",
    "    value of the gaussian\n",
    "    \"\"\"\n",
    "    \n",
    "    determinant_covariance = np.linalg.det(covariance)\n",
    "    determinant_covariance_root = np.sqrt(determinant_covariance)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "    gaussian_pi_coeff = 1.0 / np.power((2 * np.pi), (dimension / 2))\n",
    "    data_mean_diff = (data_point - mean)\n",
    "    data_mean_diff_transpose = data_mean_diff.T     \n",
    "    return (gaussian_pi_coeff) * (determinant_covariance_root) * np.exp(-0.5 * np.matmul(np.matmul(data_mean_diff, covariance_inverse), data_mean_diff_transpose))\n",
    "\n",
    "# Perform the expectation step\n",
    "def expectation_step(n, d, k, data, weights_gaussian, mean_gaussian, covariance_matrix_gaussian):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    n - the number of data-points\n",
    "    d - dimension of gaussian\n",
    "    k - number of gaussians\n",
    "    data - data to be trained on of size (n x d)\n",
    "    weights_gaussian - weight of gaussians of size (k)\n",
    "    mean_gaussian - mean of gaussians of size (k x d)\n",
    "    covariance_matrix_gaussian - covariance of gaussians of size (k x d x d)\n",
    "    probability_values - probability of the datapoint being in a gaussian of size (n x k)\n",
    "    \n",
    "    Outputs:\n",
    "    probabilities - probability array of size (n x k)\n",
    "    \"\"\"\n",
    "    \n",
    "    # create empty array of list of probabilities\n",
    "    probabilities = []\n",
    "    \n",
    "    # iterate through each item\n",
    "    for j in range(0, n):\n",
    "        \n",
    "        # calculate probability of a point being in the k-gaussians\n",
    "        probability_x = 0.0\n",
    "        for i in range(0, k):\n",
    "            probability_x = probability_x + gaussian_estimation(data[j], mean_gaussian[i], covariance_matrix_gaussian[i], d) * weights_gaussian[i]\n",
    "        probability_x_temp = []    \n",
    "        for i in range(0, k):\n",
    "            val = (gaussian_estimation(data[j], mean_gaussian[i], covariance_matrix_gaussian[i], d) * weights_gaussian[i]) / probability_x\n",
    "            probability_x_temp.append(val)\n",
    "        \n",
    "        # append probabilities of a point being in k-gaussians of size (1 x k)\n",
    "        probabilities.append(probability_x_temp)\n",
    "    return np.array(probabilities)\n",
    "\n",
    "\n",
    "# The maximization step will compute the mean, the mixture prior and the Covariance for each of the gaussian\"\n",
    "def maximization_gaussian(data_probabilities, input_data, initial_mixture_coeff, initial_mean_gaussian, initial_covariance_gaussian):\n",
    "    \"\"\"\n",
    "    K: Number of components of the gaussian mixture\n",
    "    input_data: (NxD) which is number of datapoints times the dimension of each data point\n",
    "    phi_k: List of mixture coefficients of size K\n",
    "    mean_k: List of mean for the kth component of the Gaussian Mixture of the size (Kxd)\n",
    "    sigma_square_k: Variance of the kth component of the mixture model (Kxdxd)\n",
    "    data_probabilities: Probability of the ith datapoint coming from gaussian k. The size of this matrix is (nxk)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initializations for mixture coefficients, mean and covariance of the gaussian\n",
    "    \n",
    "    phi_k = initial_mixture_coeff\n",
    "    mean_k = initial_mean_gaussian\n",
    "    covariance = initial_covariance_gaussian\n",
    "    \n",
    "    # Number of Gaussians\n",
    "    K = data_probabilities.shape[1]\n",
    "    \n",
    "    # Calculation for mixture model coefficients phi_k\"\n",
    "    phi_k = np.mean(data_probabilities, axis = 0)\n",
    "    \n",
    "    # Calculation of the mean for each k gaussian\n",
    "    mean_k = np.matmul(data_probabilities.T, input_data) / np.sum(data_probabilities, axis = 0)[:,np.newaxis]\n",
    "    \n",
    "    #Calculation of the Variance for each kth Gaussian Distribution\n",
    "    \n",
    "    # Loop over each Gaussian\n",
    "    for k in range(K):\n",
    "        \n",
    "        # Compute the difference of the ith data point with the kth gaussian mean\n",
    "        x = input_data - mean_k[k,:]\n",
    "        \n",
    "        # Compute the transpose\n",
    "        x_transpose = x.T\n",
    "        \n",
    "        # Convert the kth column of the probability matrix into a sparse diagonal matrix\n",
    "        probability_diag = np.diag(data_probabilities[:,k])\n",
    "        covariance_numerator = np.matmul(np.matmul(probability_diag, x) , x_transpose)\n",
    "        \n",
    "        # The covariance numerator is again a diagonal matrix whose elements we need to sum\n",
    "        # k = 0 signifies take the main diagonal\n",
    "        covariance_numerator = np.sum(np.diag(covariance_numerator,k=0))\n",
    "        \n",
    "        # Compute the covariance\n",
    "        covariance[k,:,:] = covariance_numerator /  np.sum(data_probabilities,axis=0)[:,np.newaxis][k]\n",
    "    \n",
    "    return phi_k , mean_k , covariance\n",
    "\n",
    "# run e-m algorithm\n",
    "def run_expectation_maximization_algorithm(n, d, k, iterations, data):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    n - number of data-points\n",
    "    d - dimension of gaussian\n",
    "    k - number of gaussians\n",
    "    iterations - number of iterations \n",
    "    data - training data, size (n x d)\n",
    "    \n",
    "    Outputs:\n",
    "    weights_gaussian - weight of the gaussians, size (k)\n",
    "    mean_gaussian - mean of the gaussians, size (k x d)\n",
    "    covariance_matrix_gaussian - covariance of the gaussians, size (k x d x d)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialise step\n",
    "    (mixture_coeffs, mean_gaussian, covariance_matrix_gaussian, probability_values) = initialise_step(n, d, k)\n",
    "    \n",
    "    # run for fixed iterations\n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        # m-step\n",
    "        (weights_gaussian, mean_gaussian, covariance_matrix_gaussian) = maximization_gaussian(probability_values,data,mixture_coeffs,mean_gaussian,covariance_matrix_gaussian)\n",
    "        \n",
    "        # e-step\n",
    "        probability_values = expectation_step(n, d, k, data, mixture_coeffs, mean_gaussian, covariance_matrix_gaussian)\n",
    "            \n",
    "    # return answer\n",
    "    return (weights_gaussian, mean_gaussian, covariance_matrix_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for row in range(img2.shape[0]):\n",
    "    for col in range(img2.shape[1]):\n",
    "        val = []\n",
    "        val.append(img2[row, col, 2])\n",
    "        data.append(val)\n",
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(weights_gaussian, mean_gaussian, covariance_matrix_gaussian) = run_expectation_maximization_algorithm(2500, 1, 2, 50, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(covariance_matrix_gaussian.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "x = []\n",
    "for i in range(0, 256):\n",
    "    x.append(i)\n",
    "    output = gaussian_estimation(i, mean_gaussian[0], covariance_matrix_gaussian[0], 1) * weights_gaussian[0]\n",
    "    y.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
