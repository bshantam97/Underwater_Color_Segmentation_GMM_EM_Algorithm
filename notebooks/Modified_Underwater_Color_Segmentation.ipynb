{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the average colour histogram for each of the RGB Colour channels\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "\n",
    "path_to_image_buoy1 = 'C:\\\\Users\\\\shant\\\\Underwater_Color_Segmentation_GMM_EM_Algorithm\\\\data\\\\buoy1\\\\train\\\\buoy156.png'\n",
    "path_to_image_buoy2 = 'C:\\\\Users\\\\shant\\\\Underwater_Color_Segmentation_GMM_EM_Algorithm\\\\data\\\\buoy2\\\\train\\\\buoy108.png'\n",
    "path_to_image_buoy3 = 'C:\\\\Users\\\\shant\\\\Underwater_Color_Segmentation_GMM_EM_Algorithm\\\\data\\\\buoy3\\\\train\\\\buoy28.png'\n",
    "img1 = cv2.imread(path_to_image_buoy1)\n",
    "img2 = cv2.imread(path_to_image_buoy2)\n",
    "img3 = cv2.imread(path_to_image_buoy3)\n",
    "cv2.imshow('img1',img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise step of em algorithm\n",
    "def initialise_step(n, d, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    n - number of datapoints\n",
    "    d - dimension of the gaussian\n",
    "    k - number of the gaussians\n",
    "    \n",
    "    Outputs:\n",
    "    weights_gaussian - weight of the gaussians, size (k)\n",
    "    mean_gaussian - mean of the gaussians, size (k x d)\n",
    "    covariance_matrix_gaussian - covariance of the gaussians, size (k x d x d)\n",
    "    probability_values - probability of the datapoint being in the k-gaussians, size (n x k)\n",
    "    \"\"\"\n",
    "        \n",
    "    # initialise weights\n",
    "    weights_gaussian = np.zeros(k)\n",
    "    for index in range(0, k):\n",
    "        weights_gaussian[index] = (1.0 / k)\n",
    "    \n",
    "    # initialise mean\n",
    "    mean_gaussian = np.zeros((k, d))\n",
    "    \n",
    "    # initialise covariance\n",
    "    covariance_matrix_gaussian = np.zeros((k, d, d))\n",
    "    \n",
    "    # randomly initialise probability\n",
    "    probability_values = np.zeros((n, k))\n",
    "    for index in range(0, n):\n",
    "        probability_values[index][np.random.randint(0, k)] = 1\n",
    "        \n",
    "    # return the arrays\n",
    "    return (weights_gaussian, mean_gaussian, covariance_matrix_gaussian, probability_values)\n",
    "\n",
    "# Fit a gaussian using the datapoints obtained using the histogram\n",
    "def fit_gaussian(image):\n",
    "    \n",
    "    color = ('b' , 'g' , 'r') # The number of color channels\n",
    "    \n",
    "    for i, col in enumerate(color):\n",
    "        \n",
    "        # Calculate the histogram for the Red Green and Blue color channel\n",
    "        # If input is grayscale the channels = [0] but for color image the channels can be [0], [1], [2]\n",
    "        histr = cv2.calcHist([image],[i],None,[256],[0,256])\n",
    "\n",
    "        (mu , sigma) = norm.fit(histr) # Maximum likelihood estimate\n",
    "        bins = np.linspace(0,255,256)\n",
    "        print(\"mu:\" + str(mu) + \"sigma:\" + str(sigma))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(bins, norm.pdf(bins,mu,(sigma)),color=col); plt.xlim([0,256])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(histr,color = col); plt.xlim([0,256])\n",
    "    plt.show()\n",
    "\n",
    "# gaussian estimation for expectation step\n",
    "def gaussian_estimation(data_point, mean, covariance, dimension):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    data_point - data point of the gaussian, size (1 x d)\n",
    "    mean - mean of the gaussian, size (1 x d)\n",
    "    covariance - covariance of the gaussian, size (1 x d x d)\n",
    "    dimension - dimension of the gaussian\n",
    "    \n",
    "    Outputs:\n",
    "    value of the gaussian\n",
    "    \"\"\"\n",
    "    \n",
    "    determinant_covariance = np.linalg.det(covariance)\n",
    "    determinant_covariance_root = np.sqrt(determinant_covariance)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "    gaussian_pi_coeff = 1.0 / np.power((2 * np.pi), (dimension / 2))\n",
    "    data_mean_diff = (data_point - mean)\n",
    "    data_mean_diff_transpose = data_mean_diff.T     \n",
    "    return (gaussian_pi_coeff) * (determinant_covariance_root) * np.exp(-0.5 * np.matmul(np.matmul(data_mean_diff, covariance_inverse), data_mean_diff_transpose))\n",
    "\n",
    "# Perform the expectation step\n",
    "def expectation_step(n, d, k, data, weights_gaussian, mean_gaussian, covariance_matrix_gaussian):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    n - the number of data-points\n",
    "    d - dimension of gaussian\n",
    "    k - number of gaussians\n",
    "    data - data to be trained on of size (n x d)\n",
    "    weights_gaussian - weight of gaussians of size (k)\n",
    "    mean_gaussian - mean of gaussians of size (k x d)\n",
    "    covariance_matrix_gaussian - covariance of gaussians of size (k x d x d)\n",
    "    probability_values - probability of the datapoint being in a gaussian of size (n x k)\n",
    "    \n",
    "    Outputs:\n",
    "    probabilities - probability array of size (n x k)\n",
    "    \"\"\"\n",
    "    \n",
    "    # create empty array of list of probabilities\n",
    "    probabilities = []\n",
    "    \n",
    "    # iterate through each item\n",
    "    for j in range(0, n):\n",
    "        \n",
    "        # calculate probability of a point being in the k-gaussians\n",
    "        probability_x = 0.0\n",
    "        for i in range(0, k):\n",
    "            probability_x = probability_x + gaussian_estimation(data[j], mean_gaussian[i], covariance_matrix_gaussian[i], d) * weights_gaussian[i]\n",
    "        probability_x_temp = []    \n",
    "        for i in range(0, k):\n",
    "            val = (gaussian_estimation(data[j], mean_gaussian[i], covariance_matrix_gaussian[i], d) * weights_gaussian[i]) / probability_x\n",
    "            probability_x_temp.append(val)\n",
    "        \n",
    "        # append probabilities of a point being in k-gaussians of size (1 x k)\n",
    "        probabilities.append(probability_x_temp)\n",
    "    return np.array(probabilities)\n",
    "\n",
    "\n",
    "# The maximization step will compute the mean, the mixture prior and the Covariance for each of the gaussian\"\n",
    "def maximization_gaussian(data_probabilities, input_data, initial_mixture_coeff, initial_mean_gaussian, initial_covariance_gaussian):\n",
    "    \"\"\"\n",
    "    K: Number of components of the gaussian mixture\n",
    "    input_data: (NxD) which is number of datapoints times the dimension of each data point\n",
    "    phi_k: List of mixture coefficients of size K\n",
    "    mean_k: List of mean for the kth component of the Gaussian Mixture of the size (Kxd)\n",
    "    sigma_square_k: Variance of the kth component of the mixture model (Kxdxd)\n",
    "    data_probabilities: Probability of the ith datapoint coming from gaussian k. The size of this matrix is (nxk)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initializations for mixture coefficients, mean and covariance of the gaussian\n",
    "    \n",
    "    phi_k = initial_mixture_coeff\n",
    "    mean_k = initial_mean_gaussian\n",
    "    covariance = initial_covariance_gaussian\n",
    "    \n",
    "    # Number of Gaussians\n",
    "    K = data_probabilities.shape[1]\n",
    "    \n",
    "    # Calculation for mixture model coefficients phi_k\"\n",
    "    phi_k = np.mean(data_probabilities, axis = 0)\n",
    "    \n",
    "    # Calculation of the mean for each k gaussian\n",
    "    mean_k = np.matmul(data_probabilities.T, input_data) / np.sum(data_probabilities, axis = 0)[:,np.newaxis]\n",
    "    \n",
    "    #Calculation of the Variance for each kth Gaussian Distribution\n",
    "    \n",
    "    # Loop over each Gaussian\n",
    "    for k in range(K):\n",
    "        \n",
    "        # Compute the difference of the ith data point with the kth gaussian mean\n",
    "        x = input_data - mean_k[k,:]\n",
    "        \n",
    "        # Compute the transpose\n",
    "        x_transpose = x.T\n",
    "        \n",
    "        # Convert the kth column of the probability matrix into a sparse diagonal matrix\n",
    "        probability_diag = np.diag(data_probabilities[:,k])\n",
    "        covariance_numerator = np.matmul(np.matmul(probability_diag, x) , x_transpose)\n",
    "        \n",
    "        # The covariance numerator is again a diagonal matrix whose elements we need to sum\n",
    "        # k = 0 signifies take the main diagonal\n",
    "        covariance_numerator = np.sum(np.diag(covariance_numerator,k=0))\n",
    "        \n",
    "        # Compute the covariance\n",
    "        covariance[k,:,:] = covariance_numerator /  np.sum(data_probabilities,axis=0)[:,np.newaxis][k]\n",
    "    \n",
    "    return phi_k , mean_k , covariance\n",
    "\n",
    "# run e-m algorithm\n",
    "def run_expectation_maximization_algorithm(n, d, k, iterations, data):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    n - number of data-points\n",
    "    d - dimension of gaussian\n",
    "    k - number of gaussians\n",
    "    iterations - number of iterations \n",
    "    data - training data, size (n x d)\n",
    "    \n",
    "    Outputs:\n",
    "    weights_gaussian - weight of the gaussians, size (k)\n",
    "    mean_gaussian - mean of the gaussians, size (k x d)\n",
    "    covariance_matrix_gaussian - covariance of the gaussians, size (k x d x d)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialise step\n",
    "    (mixture_coeffs, mean_gaussian, covariance_matrix_gaussian, probability_values) = initialise_step(n, d, k)\n",
    "    \n",
    "    # run for fixed iterations\n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        # m-step\n",
    "        (weights_gaussian, mean_gaussian, covariance_matrix_gaussian) = maximization_gaussian(probability_values,data,mixture_coeffs,mean_gaussian,covariance_matrix_gaussian)\n",
    "        \n",
    "        # e-step\n",
    "        probability_values = expectation_step(n, d, k, data, mixture_coeffs, mean_gaussian, covariance_matrix_gaussian)\n",
    "            \n",
    "    # return answer\n",
    "    return (weights_gaussian, mean_gaussian, covariance_matrix_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for row in range(img2.shape[0]):\n",
    "    for col in range(img2.shape[1]):\n",
    "        val = []\n",
    "        val.append(img2[row, col, 2])\n",
    "        data.append(val)\n",
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(weights_gaussian, mean_gaussian, covariance_matrix_gaussian) = run_expectation_maximization_algorithm(2500, 1, 2, 50, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(covariance_matrix_gaussian.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
